{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTzMWVRrdUCn"
      },
      "outputs": [],
      "source": [
        "pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CqRFchzdkqh"
      },
      "outputs": [],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkAhKs3Edluh",
        "outputId": "28b6e6d4-a222-4dd8-bc7a-fbcf9e998836"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io \u001b[38;5;28;01mas\u001b[39;00m sio\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from preclassify import dicomp, hcluster\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy import io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from einops.layers.torch import Rearrange\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from timm.models.layers import trunc_normal_\n",
        "from torch.autograd import Function\n",
        "from torch_wavelets import DWT_2D, IDWT_2D\n",
        "import pywt\n",
        "from skimage import io, measure\n",
        "import random\n",
        "import math\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lwfNoETdpiJ"
      },
      "outputs": [],
      "source": [
        "def pair(t):\n",
        "    return t if isinstance(t, tuple) else (t, t)\n",
        "\n",
        "\n",
        "seed = 3407\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "seed_everything(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXX-qZhHdtJI"
      },
      "outputs": [],
      "source": [
        "def image_normalize(data):\n",
        "    import math\n",
        "    _mean = np.mean(data)\n",
        "    _std = np.std(data)\n",
        "    npixel = np.size(data) * 1.0\n",
        "    min_stddev = 1.0 / math.sqrt(npixel)\n",
        "    return (data - _mean) / max(_std, min_stddev)\n",
        "\n",
        "\n",
        "def image_padding(data, r):\n",
        "    if len(data.shape) == 3:\n",
        "        data_new = np.lib.pad(data, ((r, r), (r, r), (0, 0)), 'constant', constant_values=0)\n",
        "        return data_new\n",
        "    if len(data.shape) == 2:\n",
        "        data_new = np.lib.pad(data, r, 'constant', constant_values=0)\n",
        "        return data_new\n",
        "\n",
        "\n",
        "def arr(length):\n",
        "    arr = np.arange(length - 1)\n",
        "    # print(arr)\n",
        "    random.shuffle(arr)\n",
        "    # print(arr)\n",
        "    return arr\n",
        "\n",
        "\n",
        "def createTrainingCubes(X, y, patch_size):\n",
        "    margin = int((patch_size - 1) / 2) + 1\n",
        "    zeroPaddedX = image_padding(X, margin)\n",
        "    ele_num1 = np.sum(y == 1)\n",
        "    ele_num2 = np.sum(y == 2)\n",
        "    patchesData_1 = np.zeros((ele_num1, patch_size, patch_size, X.shape[2]))\n",
        "    patchesLabels_1 = np.zeros(ele_num1)\n",
        "    patchesData_2 = np.zeros((ele_num2, patch_size, patch_size, X.shape[2]))\n",
        "    patchesLabels_2 = np.zeros(ele_num2)\n",
        "\n",
        "    patchIndex_1 = 0\n",
        "    patchIndex_2 = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            # remove uncertainty pixels\n",
        "            if y[r - margin, c - margin] == 1:\n",
        "                patch_1 = zeroPaddedX[r - margin:r + margin, c - margin:c + margin]\n",
        "                patchesData_1[patchIndex_1, :, :, :] = patch_1\n",
        "                patchesLabels_1[patchIndex_1] = y[r - margin, c - margin]\n",
        "                patchIndex_1 = patchIndex_1 + 1\n",
        "            elif y[r - margin, c - margin] == 2:\n",
        "                patch_2 = zeroPaddedX[r - margin:r + margin, c - margin:c + margin]\n",
        "                patchesData_2[patchIndex_2, :, :, :] = patch_2\n",
        "                patchesLabels_2[patchIndex_2] = y[r - margin, c - margin]\n",
        "                patchIndex_2 = patchIndex_2 + 1\n",
        "    patchesLabels_1 = patchesLabels_1 - 1\n",
        "    patchesLabels_2 = patchesLabels_2 - 1\n",
        "\n",
        "    arr_1 = arr(len(patchesData_1))\n",
        "    arr_2 = arr(len(patchesData_2))\n",
        "    train_len = 10000\n",
        "    pdata = np.zeros((train_len, patch_size, patch_size, X.shape[2]))\n",
        "    plabels = np.zeros(train_len)\n",
        "    for i in range(7000):\n",
        "        pdata[i, :, :, :] = patchesData_1[arr_1[i], :, :, :]\n",
        "        plabels[i] = patchesLabels_1[arr_1[i]]\n",
        "    for j in range(7000, train_len):\n",
        "        pdata[j, :, :, :] = patchesData_2[arr_2[j - 7000], :, :, :]\n",
        "        plabels[j] = patchesLabels_2[arr_2[j - 7000]]\n",
        "\n",
        "    return pdata, plabels\n",
        "\n",
        "\n",
        "def createTestingCubes(X, patch_size):\n",
        "    margin = int((patch_size - 1) / 2) + 1\n",
        "    zeroPaddedX = image_padding(X, margin)\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], patch_size, patch_size, X.shape[2]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin, c - margin:c + margin]\n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchIndex = patchIndex + 1\n",
        "    return patchesData\n",
        "\n",
        "\n",
        "#  Inputs:  gtImg  = ground truth image\n",
        "#           tstImg = change map\n",
        "#  Outputs: FA  = False alarms\n",
        "#           MA  = Missed alarms\n",
        "#           OE  = Overall error\n",
        "#           PCC = Overall accuracy\n",
        "def evaluate(gtImg, tstImg):\n",
        "    gtImg[np.where(gtImg > 128)] = 255\n",
        "    gtImg[np.where(gtImg < 128)] = 0\n",
        "    tstImg[np.where(tstImg > 128)] = 255\n",
        "    tstImg[np.where(tstImg < 128)] = 0\n",
        "    [ylen, xlen] = gtImg.shape\n",
        "    FA = 0\n",
        "    MA = 0\n",
        "    label_0 = np.sum(gtImg == 0)\n",
        "    label_1 = np.sum(gtImg == 255)\n",
        "    print(label_0)\n",
        "    print(label_1)\n",
        "\n",
        "    for j in range(0, ylen):\n",
        "        for i in range(0, xlen):\n",
        "            if gtImg[j, i] == 0 and tstImg[j, i] != 0:\n",
        "                FA = FA + 1\n",
        "            if gtImg[j, i] != 0 and tstImg[j, i] == 0:\n",
        "                MA = MA + 1\n",
        "\n",
        "    OE = FA + MA\n",
        "    PCC = 1 - OE / (ylen * xlen)\n",
        "    PRE = ((label_1 + FA - MA) * label_1 + (label_0 + MA - FA) * label_0) / ((ylen * xlen) * (ylen * xlen))\n",
        "    KC = (PCC - PRE) / (1 - PRE)\n",
        "    print(' Change detection results ==>')\n",
        "    print(' ... ... FP:  ', FA)\n",
        "    print(' ... ... FN:  ', MA)\n",
        "    print(' ... ... OE:  ', OE)\n",
        "    print(' ... ... PCC: ', format(PCC * 100, '.2f'))\n",
        "    print(' ... ... KC: ', format(KC * 100, '.2f'))\n",
        "\n",
        "\n",
        "def postprocess1(res):\n",
        "    res_new = res\n",
        "    res = measure.label(res, connectivity=2)\n",
        "    # print(res)\n",
        "    num = res.max()\n",
        "    # print(num)\n",
        "    for i in range(1, num + 1):\n",
        "        idy, idx = np.where(res == i)\n",
        "        if len(idy) <= 15:\n",
        "            res_new[idy, idx] = 0.5\n",
        "    return res_new\n",
        "\n",
        "\n",
        "def postprocess(res):\n",
        "    res_new = res\n",
        "    res = measure.label(res, connectivity=2)\n",
        "    # print(res)\n",
        "    num = res.max()\n",
        "    # print(num)\n",
        "    for i in range(1, num + 1):\n",
        "        idy, idx = np.where(res == i)\n",
        "        if len(idy) <= 20:\n",
        "            res_new[idy, idx] = 0\n",
        "    return res_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7JnDkesdxSo"
      },
      "outputs": [],
      "source": [
        "\n",
        "im1_path = '/content/Sulzberger2_1.bmp'\n",
        "im2_path = '/content/Sulzberger2_2.bmp'\n",
        "imgt_path = '/content/Sulzberger2_gt.bmp'\n",
        "\n",
        "\n",
        "patch_size = 8\n",
        "\n",
        "\n",
        "if im1_path == '/content/Yellow_River_1.bmp':\n",
        "  im1 = io.imread(im1_path).astype(np.float32)\n",
        "  im2 = io.imread(im2_path).astype(np.float32)\n",
        "  im_gt = io.imread(imgt_path).astype(np.float32)\n",
        "else:\n",
        "  im1 = io.imread(im1_path)[:, :, 0].astype(np.float32)\n",
        "  im2 = io.imread(im2_path)[:, :, 0].astype(np.float32)\n",
        "  im_gt = io.imread(imgt_path)[:, :, 0].astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "im_di = dicomp(im1, im2)\n",
        "ylen, xlen = im_di.shape\n",
        "pix_vec = im_di.reshape([ylen * xlen, 1])\n",
        "\n",
        "preclassify_lab = hcluster(pix_vec, im_di)\n",
        "print('... ... hiearchical clustering finished !!!')\n",
        "\n",
        "mdata = np.zeros([im1.shape[0], im1.shape[1], 3], dtype=np.float32)\n",
        "mdata[:, :, 0] = im1\n",
        "mdata[:, :, 1] = im2\n",
        "mdata[:, :, 2] = im_di\n",
        "mlabel = preclassify_lab\n",
        "\n",
        "x_train, y_train = createTrainingCubes(mdata, mlabel, patch_size)\n",
        "x_train = x_train.transpose(0, 3, 1, 2)\n",
        "# print(y_train.shape) #[10000]\n",
        "x_test = createTestingCubes(mdata, patch_size)\n",
        "x_test = x_test.transpose(0, 3, 1, 2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class TrainDS(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = x_train.shape[0]\n",
        "        self.x_data = torch.FloatTensor(x_train)\n",
        "        self.y_data = torch.LongTensor(y_train)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "trainset = TrainDS()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIYcutYBejcI"
      },
      "outputs": [],
      "source": [
        "class WaveAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, sr_ratio, dim, heads, dropout):\n",
        "        super(WaveAttention, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.dim = dim\n",
        "        head_dim = dim // heads\n",
        "        self.head_dim = dim // heads\n",
        "        self.sr_ratio = sr_ratio\n",
        "        self.scale = head_dim ** -0.5\n",
        "        self.dwt = DWT_2D(wave=\"haar\")\n",
        "        self.idwt = IDWT_2D(wave=\"haar\")\n",
        "\n",
        "        self.reduce = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim // 4, kernel_size=1, padding=0, stride=1),\n",
        "            nn.BatchNorm2d(dim // 4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.filter = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=1, stride=1, groups=1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.q = nn.Linear(dim, dim)\n",
        "        self.kv = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, dim * 2)\n",
        "        )\n",
        "\n",
        "        self.kv_embed = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio) if sr_ratio > 1 else nn.Identity()\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(dim + dim // 4, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        B, N, C = x.shape\n",
        "        q = self.q(x).reshape(B, N, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        # checkShape(\"q\", q)\n",
        "        x = x.view(B, H, W, C).permute(0, 3, 1, 2)\n",
        "        x = self.reduce(x)\n",
        "        x = torch.tensor(x, device=device).type(torch.float16)\n",
        "        x_dwt = self.dwt(x)\n",
        "        x_dwt = x_dwt.float()\n",
        "        x_dwt = self.filter(x_dwt)\n",
        "\n",
        "        x_dwt = x_dwt.half()\n",
        "        x_idwt = self.idwt(x_dwt)\n",
        "        x_idwt = x_idwt.view(B, -1, x_idwt.size(-2) * x_idwt.size(-1)).transpose(1, 2)\n",
        "\n",
        "        x_dwt = x_dwt.float()\n",
        "        kv = self.kv_embed(x_dwt).reshape(B, C, -1).permute(0, 2, 1)\n",
        "        kv = self.kv(kv).reshape(B, -1, 2, self.heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        k = kv[0]\n",
        "        v = kv[1]\n",
        "        attn = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        x = torch.matmul(attn, v).transpose(1, 2).reshape(B, N, C)  # N ->H*W\n",
        "        x = self.proj(torch.cat([x, x_idwt], dim=-1))\n",
        "        return x\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "        elif isinstance(m, nn.Conv2d):\n",
        "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "            fan_out //= m.groups\n",
        "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "class WSM(nn.Module):\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool='cls', channels=3,\n",
        "                 dim_head=64, dropout=0., emb_dropout=0.):\n",
        "        super().__init__()\n",
        "        image_height, image_width = pair(image_size)\n",
        "        patch_height, patch_width = pair(patch_size)\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be ' \\\n",
        "                                                                                    'divisible by the patch size. '\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "        patch_dim = channels * patch_height * patch_width\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "        self.transformer = WaveAttention(sr_ratio=2, dim=dim, heads=heads, dropout=dropout)\n",
        "        self.reshape = Rearrange('b (h w) (p1 p2  c) -> b (h p1) (w p2) c', p1=patch_height, p2=patch_width,\n",
        "                                 h=image_height // patch_height)\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.to_patch_embedding(img)\n",
        "        x = self.transformer(x, H=4, W=4)\n",
        "        x = self.reshape(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "wsm = WSM(image_size=8, patch_size=2, num_classes=2, dim=12, depth=6, heads=4, mlp_dim=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxQBIBqBezQ5"
      },
      "outputs": [],
      "source": [
        "class BiAttn(nn.Module):\n",
        "    def __init__(self, in_channels, act_ratio=0.5, act_fn=nn.GELU, gate_fn=nn.Sigmoid):\n",
        "        super().__init__()\n",
        "        reduce_channels = int(in_channels * act_ratio)\n",
        "        self.norm = nn.LayerNorm(in_channels)\n",
        "        self.global_reduce = nn.Linear(in_channels, reduce_channels)\n",
        "        self.local_reduce = nn.Linear(in_channels, reduce_channels)\n",
        "        self.act_fn = act_fn()\n",
        "        self.channel_select = nn.Linear(reduce_channels, in_channels)\n",
        "        self.spatial_select = nn.Linear(reduce_channels * 2, 1)\n",
        "        self.gate_fn = gate_fn()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ori_x = x\n",
        "\n",
        "        x = self.norm(x)\n",
        "        copy = x\n",
        "        copy = copy.permute(0, 3, 1, 2)\n",
        "        x_global = F.avg_pool2d(copy, x.shape[2], x.shape[3])\n",
        "        x_global = x_global.permute(0, 2, 3, 1)\n",
        "        x_global = self.act_fn(self.global_reduce(x_global))\n",
        "        x_local = self.act_fn(self.local_reduce(x))\n",
        "\n",
        "        c_attn = self.channel_select(x_global)\n",
        "        c_attn = self.gate_fn(c_attn)\n",
        "        s_attn = self.spatial_select(torch.cat([x_local, x_global.repeat(1, x.shape[1], x.shape[2], 1)], dim=-1))\n",
        "        s_attn = self.gate_fn(s_attn)\n",
        "        attn = c_attn * s_attn\n",
        "        return ori_x * attn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-1TVkvDe5tA"
      },
      "outputs": [],
      "source": [
        "class ConcactFeature(nn.Module):\n",
        "    def __init__(self, dim=3):\n",
        "        super(ConcactFeature, self).__init__()\n",
        "        self.catConv = nn.Conv2d(3, 3, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm([3, patch_size, patch_size])\n",
        "        self.conv = nn.Conv2d(3, 3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.catConv(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class WBANet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WBANet, self).__init__()\n",
        "        self.wsm = wsm\n",
        "        self.bam = BiAttn(in_channels=3)\n",
        "        self.cf = ConcactFeature()\n",
        "        self.linear1 = nn.Linear(patch_size * patch_size * 3, 20)\n",
        "        self.linear2 = nn.Linear(20, 2)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.catConv = nn.Conv2d(6, 3, kernel_size=1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        wsmOut = self.wsm(img)\n",
        "        bamOut = self.bam(img.permute(0, 2, 3, 1))\n",
        "        catOut = torch.cat((wsmOut, bamOut), 3).permute(0, 3, 1, 2)\n",
        "        catOut = self.catConv(catOut)\n",
        "\n",
        "        x = self.cf(catOut)\n",
        "\n",
        "        out1 = x.view(x.size(0), -1)  # 128 192\n",
        "        out = self.linear1(out1)\n",
        "        out = self.linear2(out)\n",
        "        return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6CDRQhcgpuh"
      },
      "outputs": [],
      "source": [
        "gamma = 0.75\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = WBANet().to(device)\n",
        "lr = 5e-3\n",
        "epoch = 10\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "start_time = time.time()\n",
        "for epoch in range(epoch):\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    for data, label in tqdm(train_loader):\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == label).float().mean()\n",
        "        epoch_accuracy += acc / len(train_loader)\n",
        "        epoch_loss += loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch : {epoch + 1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "\n",
        "print(f\"train run time: {execution_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XvXCFtCmhScB"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.eval()\n",
        "outputs = np.zeros((ylen, xlen))\n",
        "start_time = time.time()\n",
        "for i in range(ylen):\n",
        "    for j in range(xlen):\n",
        "        if preclassify_lab[i, j] != 1.5:\n",
        "            outputs[i, j] = preclassify_lab[i, j]\n",
        "        else:\n",
        "            img_patch = x_test[i * xlen + j, :, :, :]\n",
        "            img_patch = img_patch.reshape(1, img_patch.shape[0], img_patch.shape[1], img_patch.shape[2])\n",
        "            img_patch = torch.FloatTensor(img_patch).to(device)\n",
        "            prediction = model(img_patch)\n",
        "            prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
        "            outputs[i, j] = prediction + 1\n",
        "\n",
        "    if (i + 1) % 50 == 0:\n",
        "        print('... ... row', i + 1, ' handling ... ...')\n",
        "\n",
        "\n",
        "outputs = outputs - 1\n",
        "res = outputs * 255\n",
        "res = postprocess(res)\n",
        "evaluate(im_gt, res)\n",
        "plt.imshow(res, 'gray')\n",
        "plt.axis('off')  # remove coordinate axis\n",
        "plt.xticks([])  # remove x axis\n",
        "plt.yticks([])  # remove y axis\n",
        "\n",
        "plt.show()\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(f\"test run time: {execution_time:.4f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwDWgu5Tfs8S"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}